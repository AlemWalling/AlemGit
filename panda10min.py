Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)] on win32
Type "help", "copyright", "credits" or "license" for more information.
>>> import pandas as pd
>>> import numpy as np
>>> import matplotlib as plt
>>> s = pd.Series([1,3,5,np.nan,6,8])
>>> s
0    1.0
1    3.0
2    5.0
3    NaN
4    6.0
5    8.0
dtype: float64
>>> dates = pd.date_range('20130101', periods=6)
>>> dates
DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',
               '2013-01-05', '2013-01-06'],
              dtype='datetime64[ns]', freq='D')
>>> df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD')
... df
  File "<stdin>", line 2
    df
     ^
SyntaxError: invalid syntax
>>> df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))
>>> df
                   A         B         C         D
2013-01-01 -1.516782 -0.086482  0.012133  0.962081
2013-01-02  0.650630  0.144697  1.441690  0.963953
2013-01-03  0.093990  0.446636 -0.395451 -0.685677
2013-01-04  0.826292  0.624639 -2.345848 -2.845692
2013-01-05  0.007630  0.897725  0.315542 -0.211737
2013-01-06 -0.450114 -0.486287 -0.144323  1.652280
>>> df2 = pd.DataFrame({ 'A' : 1.,
...     'B' : pd.Timestamp('20130102'),
...     'C' : pd.Series(1,index=list(range(4)),dtype='float32'),
...     'D' : np.array([3] * 4,dtype='int32'),
...     'E' : pd.Categorical(["test","train","test","train"]),
...     'F' : 'foo' })
>>> df2
     A          B    C  D      E    F
0  1.0 2013-01-02  1.0  3   test  foo
1  1.0 2013-01-02  1.0  3  train  foo
2  1.0 2013-01-02  1.0  3   test  foo
3  1.0 2013-01-02  1.0  3  train  foo
>>> df2.dtypes
A           float64
B    datetime64[ns]
C           float32
D             int32
E          category
F            object
dtype: object
>>> df2.<TAB>
  File "<stdin>", line 1
    df2.<TAB>
        ^
SyntaxError: invalid syntax
>>> df.head()
                   A         B         C         D
2013-01-01 -1.516782 -0.086482  0.012133  0.962081
2013-01-02  0.650630  0.144697  1.441690  0.963953
2013-01-03  0.093990  0.446636 -0.395451 -0.685677
2013-01-04  0.826292  0.624639 -2.345848 -2.845692
2013-01-05  0.007630  0.897725  0.315542 -0.211737
>>> df.tail(3)
                   A         B         C         D
2013-01-04  0.826292  0.624639 -2.345848 -2.845692
2013-01-05  0.007630  0.897725  0.315542 -0.211737
2013-01-06 -0.450114 -0.486287 -0.144323  1.652280
>>> df.index
DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',
               '2013-01-05', '2013-01-06'],
              dtype='datetime64[ns]', freq='D')
>>> df.columns
Index(['A', 'B', 'C', 'D'], dtype='object')
>>> df.values
array([[-1.51678231, -0.08648221,  0.01213318,  0.96208123],
       [ 0.65063044,  0.14469653,  1.44168993,  0.96395322],
       [ 0.09399047,  0.44663608, -0.39545089, -0.68567702],
       [ 0.82629185,  0.62463896, -2.34584796, -2.84569151],
       [ 0.00762964,  0.89772471,  0.31554239, -0.21173718],
       [-0.45011387, -0.48628748, -0.14432274,  1.65228035]])
>>> df.describe()
              A         B         C         D
count  6.000000  6.000000  6.000000  6.000000
mean  -0.064726  0.256821 -0.186043 -0.027465
std    0.847710  0.502935  1.236990  1.624393
min   -1.516782 -0.486287 -2.345848 -2.845692
25%   -0.335678 -0.028688 -0.332669 -0.567192
50%    0.050810  0.295666 -0.066095  0.375172
75%    0.511470  0.580138  0.239690  0.963485
max    0.826292  0.897725  1.441690  1.652280
>>> df.T
   2013-01-01  2013-01-02  2013-01-03  2013-01-04  2013-01-05  2013-01-06
A   -1.516782    0.650630    0.093990    0.826292    0.007630   -0.450114
B   -0.086482    0.144697    0.446636    0.624639    0.897725   -0.486287
C    0.012133    1.441690   -0.395451   -2.345848    0.315542   -0.144323
D    0.962081    0.963953   -0.685677   -2.845692   -0.211737    1.652280
>>> df.sort_index(axis=1, ascending=False)
                   D         C         B         A
2013-01-01  0.962081  0.012133 -0.086482 -1.516782
2013-01-02  0.963953  1.441690  0.144697  0.650630
2013-01-03 -0.685677 -0.395451  0.446636  0.093990
2013-01-04 -2.845692 -2.345848  0.624639  0.826292
2013-01-05 -0.211737  0.315542  0.897725  0.007630
2013-01-06  1.652280 -0.144323 -0.486287 -0.450114
>>> df.sort_values(by='B')
                   A         B         C         D
2013-01-06 -0.450114 -0.486287 -0.144323  1.652280
2013-01-01 -1.516782 -0.086482  0.012133  0.962081
2013-01-02  0.650630  0.144697  1.441690  0.963953
2013-01-03  0.093990  0.446636 -0.395451 -0.685677
2013-01-04  0.826292  0.624639 -2.345848 -2.845692
2013-01-05  0.007630  0.897725  0.315542 -0.211737
>>>
KeyboardInterrupt
>>> df['A']
2013-01-01   -1.516782
2013-01-02    0.650630
2013-01-03    0.093990
2013-01-04    0.826292
2013-01-05    0.007630
2013-01-06   -0.450114
Freq: D, Name: A, dtype: float64
>>> df[0:3]
                   A         B         C         D
2013-01-01 -1.516782 -0.086482  0.012133  0.962081
2013-01-02  0.650630  0.144697  1.441690  0.963953
2013-01-03  0.093990  0.446636 -0.395451 -0.685677
>>> df['20130102':'20130104']
                   A         B         C         D
2013-01-02  0.650630  0.144697  1.441690  0.963953
2013-01-03  0.093990  0.446636 -0.395451 -0.685677
2013-01-04  0.826292  0.624639 -2.345848 -2.845692
>>> df.loc[dates[0]]
A   -1.516782
B   -0.086482
C    0.012133
D    0.962081
Name: 2013-01-01 00:00:00, dtype: float64
>>> df.loc[:,['A','B']]
                   A         B
2013-01-01 -1.516782 -0.086482
2013-01-02  0.650630  0.144697
2013-01-03  0.093990  0.446636
2013-01-04  0.826292  0.624639
2013-01-05  0.007630  0.897725
2013-01-06 -0.450114 -0.486287
>>> df.loc['20130102':'20130104',['A','B']]
                   A         B
2013-01-02  0.650630  0.144697
2013-01-03  0.093990  0.446636
2013-01-04  0.826292  0.624639
>>> df.loc['20130102',['A','B']]
A    0.650630
B    0.144697
Name: 2013-01-02 00:00:00, dtype: float64
>>> df.loc[dates[0],'A']
-1.5167823125128126
>>> df.at[dates[0],'A']
-1.5167823125128126
>>> df.iloc[3]
A    0.826292
B    0.624639
C   -2.345848
D   -2.845692
Name: 2013-01-04 00:00:00, dtype: float64
>>> df.iloc[3:5,0:2]
                   A         B
2013-01-04  0.826292  0.624639
2013-01-05  0.007630  0.897725
>>> df.iloc[[1,2,4],[0,2]]
                  A         C
2013-01-02  0.65063  1.441690
2013-01-03  0.09399 -0.395451
2013-01-05  0.00763  0.315542
>>> df.iloc[1:3,:]
                  A         B         C         D
2013-01-02  0.65063  0.144697  1.441690  0.963953
2013-01-03  0.09399  0.446636 -0.395451 -0.685677
>>> df.iloc[:,1:3]
                   B         C
2013-01-01 -0.086482  0.012133
2013-01-02  0.144697  1.441690
2013-01-03  0.446636 -0.395451
2013-01-04  0.624639 -2.345848
2013-01-05  0.897725  0.315542
2013-01-06 -0.486287 -0.144323
>>> df.iloc[1,1]
0.1446965271978003
>>> df.iat[1,1]
0.1446965271978003
>>> df[df.A > 0]
                   A         B         C         D
2013-01-02  0.650630  0.144697  1.441690  0.963953
2013-01-03  0.093990  0.446636 -0.395451 -0.685677
2013-01-04  0.826292  0.624639 -2.345848 -2.845692
2013-01-05  0.007630  0.897725  0.315542 -0.211737
>>>
KeyboardInterrupt
>>> df[df > 0]
                   A         B         C         D
2013-01-01       NaN       NaN  0.012133  0.962081
2013-01-02  0.650630  0.144697  1.441690  0.963953
2013-01-03  0.093990  0.446636       NaN       NaN
2013-01-04  0.826292  0.624639       NaN       NaN
2013-01-05  0.007630  0.897725  0.315542       NaN
2013-01-06       NaN       NaN       NaN  1.652280
>>> df2 = df.copy()
>>> df2['E'] = ['one', 'one','two','three','four','three']
>>> df2
                   A         B         C         D      E
2013-01-01 -1.516782 -0.086482  0.012133  0.962081    one
2013-01-02  0.650630  0.144697  1.441690  0.963953    one
2013-01-03  0.093990  0.446636 -0.395451 -0.685677    two
2013-01-04  0.826292  0.624639 -2.345848 -2.845692  three
2013-01-05  0.007630  0.897725  0.315542 -0.211737   four
2013-01-06 -0.450114 -0.486287 -0.144323  1.652280  three
>>> df2[df2['E'].isin(['two','four'])]
                  A         B         C         D     E
2013-01-03  0.09399  0.446636 -0.395451 -0.685677   two
2013-01-05  0.00763  0.897725  0.315542 -0.211737  four
>>> s1 = pd.Series([1,2,3,4,5,6], index=pd.date_range('20130102', periods=6))
>>> s1
2013-01-02    1
2013-01-03    2
2013-01-04    3
2013-01-05    4
2013-01-06    5
2013-01-07    6
Freq: D, dtype: int64
>>> df.at[dates[0],'A'] = 0
>>> df.iat[0,1] = 0
>>> df.loc[:,'D'] = np.array([5] * len(df))
>>> df
                   A         B         C  D
2013-01-01  0.000000  0.000000  0.012133  5
2013-01-02  0.650630  0.144697  1.441690  5
2013-01-03  0.093990  0.446636 -0.395451  5
2013-01-04  0.826292  0.624639 -2.345848  5
2013-01-05  0.007630  0.897725  0.315542  5
2013-01-06 -0.450114 -0.486287 -0.144323  5
>>> df2 = df.copy()
>>> df2[df2 > 0] = -df2
>>> df2
                   A         B         C  D
2013-01-01  0.000000  0.000000 -0.012133 -5
2013-01-02 -0.650630 -0.144697 -1.441690 -5
2013-01-03 -0.093990 -0.446636 -0.395451 -5
2013-01-04 -0.826292 -0.624639 -2.345848 -5
2013-01-05 -0.007630 -0.897725 -0.315542 -5
2013-01-06 -0.450114 -0.486287 -0.144323 -5
>>> df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + ['E'])
>>> df1.loc[dates[0]:dates[1],'E'] = 1
>>> df1
                   A         B         C  D    E
2013-01-01  0.000000  0.000000  0.012133  5  1.0
2013-01-02  0.650630  0.144697  1.441690  5  1.0
2013-01-03  0.093990  0.446636 -0.395451  5  NaN
2013-01-04  0.826292  0.624639 -2.345848  5  NaN
>>> df1.dropna(how='any')
                  A         B         C  D    E
2013-01-01  0.00000  0.000000  0.012133  5  1.0
2013-01-02  0.65063  0.144697  1.441690  5  1.0
>>> df1.fillna(value=5)
                   A         B         C  D    E
2013-01-01  0.000000  0.000000  0.012133  5  1.0
2013-01-02  0.650630  0.144697  1.441690  5  1.0
2013-01-03  0.093990  0.446636 -0.395451  5  5.0
2013-01-04  0.826292  0.624639 -2.345848  5  5.0
>>> pd.isna(df1)
                A      B      C      D      E
2013-01-01  False  False  False  False  False
2013-01-02  False  False  False  False  False
2013-01-03  False  False  False  False   True
2013-01-04  False  False  False  False   True
>>> df.mean()
A    0.188071
B    0.271235
C   -0.186043
D    5.000000
dtype: float64
>>> df.mean(1)
2013-01-01    1.253033
2013-01-02    1.809254
2013-01-03    1.286294
2013-01-04    1.026271
2013-01-05    1.555224
2013-01-06    0.979819
Freq: D, dtype: float64
>>> s = pd.Series([1,3,5,np.nan,6,8], index=dates).shift(2)
>>> s
2013-01-01    NaN
2013-01-02    NaN
2013-01-03    1.0
2013-01-04    3.0
2013-01-05    5.0
2013-01-06    NaN
Freq: D, dtype: float64
>>> df.sub(s, axis='index')
                   A         B         C    D
2013-01-01       NaN       NaN       NaN  NaN
2013-01-02       NaN       NaN       NaN  NaN
2013-01-03 -0.906010 -0.553364 -1.395451  4.0
2013-01-04 -2.173708 -2.375361 -5.345848  2.0
2013-01-05 -4.992370 -4.102275 -4.684458  0.0
2013-01-06       NaN       NaN       NaN  NaN
>>> df.apply(np.cumsum)
                   A         B         C   D
2013-01-01  0.000000  0.000000  0.012133   5
2013-01-02  0.650630  0.144697  1.453823  10
2013-01-03  0.744621  0.591333  1.058372  15
2013-01-04  1.570913  1.215972 -1.287476  20
2013-01-05  1.578542  2.113696 -0.971933  25
2013-01-06  1.128429  1.627409 -1.116256  30
>>> df.apply(lambda x: x.max() - x.min())
A    1.276406
B    1.384012
C    3.787538
D    0.000000
dtype: float64
>>> s = pd.Series(np.random.randint(0, 7, size=10))
>>> s
0    0
1    0
2    2
3    3
4    2
5    5
6    4
7    1
8    1
9    1
dtype: int32
>>> s.value_counts()
1    3
2    2
0    2
5    1
4    1
3    1
dtype: int64
>>> s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat'])
>>> s.str.lower()
0       a
1       b
2       c
3    aaba
4    baca
5     NaN
6    caba
7     dog
8     cat
dtype: object
>>> df = pd.DataFrame(np.random.randn(10, 4))
>>> df
          0         1         2         3
0  1.136304  0.327679 -1.071739  0.392337
1 -2.530030  0.500871  1.781360  0.554240
2 -0.294141  0.332023  0.181133  1.729787
3 -0.046776  1.686540  0.167237 -0.300530
4  0.219241 -0.168305  0.012976 -0.359118
5  0.113550  0.757112 -0.088263  1.327825
6  0.114032 -1.146598 -1.081474 -0.490861
7 -1.178959  0.519215 -0.796635  0.966112
8 -1.360543 -0.925424 -1.001485  0.096072
9 -0.344667 -1.095559  0.318808  1.363240
>>> pieces = [df[:3], df[3:7], df[7:]]
>>> pd.concat(pieces)
          0         1         2         3
0  1.136304  0.327679 -1.071739  0.392337
1 -2.530030  0.500871  1.781360  0.554240
2 -0.294141  0.332023  0.181133  1.729787
3 -0.046776  1.686540  0.167237 -0.300530
4  0.219241 -0.168305  0.012976 -0.359118
5  0.113550  0.757112 -0.088263  1.327825
6  0.114032 -1.146598 -1.081474 -0.490861
7 -1.178959  0.519215 -0.796635  0.966112
8 -1.360543 -0.925424 -1.001485  0.096072
9 -0.344667 -1.095559  0.318808  1.363240
>>> left = pd.DataFrame({'key': ['foo', 'foo'], 'lval': [1, 2]})
>>> right = pd.DataFrame({'key': ['foo', 'foo'], 'rval': [4, 5]})
>>> left
   key  lval
0  foo     1
1  foo     2
>>> right
   key  rval
0  foo     4
1  foo     5
>>> pd.merge(left, right, on='key')
   key  lval  rval
0  foo     1     4
1  foo     1     5
2  foo     2     4
3  foo     2     5
>>> left = pd.DataFrame({'key': ['foo', 'bar'], 'lval': [1, 2]})
>>> right = pd.DataFrame({'key': ['foo', 'bar'], 'rval': [4, 5]})
>>> left
   key  lval
0  foo     1
1  bar     2
>>> right
   key  rval
0  foo     4
1  bar     5
>>> pd.merge(left, right, on='key')
   key  lval  rval
0  foo     1     4
1  bar     2     5
>>> df = pd.DataFrame(np.random.randn(8, 4), columns=['A','B','C','D'])
>>> df
          A         B         C         D
0 -0.182002  1.370228 -1.044140  1.040847
1  0.007933 -1.435309 -0.403513  1.104695
2 -0.181276 -1.293599  1.062721  0.686827
3 -1.133938  0.191472 -0.716223  0.552594
4 -0.288730 -0.065345 -1.592621 -0.211053
5 -0.219428 -0.953850 -0.732567 -0.143086
6  2.603100  0.277745  1.580109  0.314501
7  1.690416 -1.344637 -1.893174  0.755919
>>> s = df.iloc[3]
>>> df.append(s, ignore_index=True)
          A         B         C         D
0 -0.182002  1.370228 -1.044140  1.040847
1  0.007933 -1.435309 -0.403513  1.104695
2 -0.181276 -1.293599  1.062721  0.686827
3 -1.133938  0.191472 -0.716223  0.552594
4 -0.288730 -0.065345 -1.592621 -0.211053
5 -0.219428 -0.953850 -0.732567 -0.143086
6  2.603100  0.277745  1.580109  0.314501
7  1.690416 -1.344637 -1.893174  0.755919
8 -1.133938  0.191472 -0.716223  0.552594
>>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',
...     'foo', 'bar', 'foo', 'foo'],
...     'B' : ['one', 'one', 'two', 'three'
...     'two', 'two', 'one', 'three'],
...     'C' : np.random.randn(8),
...     'D' : np.random.randn(8)})
Traceback (most recent call last):
  File "<stdin>", line 6, in <module>
  File "C:\python\lib\site-packages\pandas\core\frame.py", line 330, in __init__
    mgr = self._init_dict(data, index, columns, dtype=dtype)
  File "C:\python\lib\site-packages\pandas\core\frame.py", line 461, in _init_dict
    return _arrays_to_mgr(arrays, data_names, index, columns, dtype=dtype)
  File "C:\python\lib\site-packages\pandas\core\frame.py", line 6163, in _arrays_to_mgr
    index = extract_index(arrays)
  File "C:\python\lib\site-packages\pandas\core\frame.py", line 6211, in extract_index
    raise ValueError('arrays must all be same length')
ValueError: arrays must all be same length
>>> df
          A         B         C         D
0 -0.182002  1.370228 -1.044140  1.040847
1  0.007933 -1.435309 -0.403513  1.104695
2 -0.181276 -1.293599  1.062721  0.686827
3 -1.133938  0.191472 -0.716223  0.552594
4 -0.288730 -0.065345 -1.592621 -0.211053
5 -0.219428 -0.953850 -0.732567 -0.143086
6  2.603100  0.277745  1.580109  0.314501
7  1.690416 -1.344637 -1.893174  0.755919
>>> df.groupby('A').sum()
                  B         C         D
A
-1.133938  0.191472 -0.716223  0.552594
-0.288730 -0.065345 -1.592621 -0.211053
-0.219428 -0.953850 -0.732567 -0.143086
-0.182002  1.370228 -1.044140  1.040847
-0.181276 -1.293599  1.062721  0.686827
 0.007933 -1.435309 -0.403513  1.104695
 1.690416 -1.344637 -1.893174  0.755919
 2.603100  0.277745  1.580109  0.314501
>>> df.groupby(['A','B']).sum()
                            C         D
A         B
-1.133938  0.191472 -0.716223  0.552594
-0.288730 -0.065345 -1.592621 -0.211053
-0.219428 -0.953850 -0.732567 -0.143086
-0.182002  1.370228 -1.044140  1.040847
-0.181276 -1.293599  1.062721  0.686827
 0.007933 -1.435309 -0.403513  1.104695
 1.690416 -1.344637 -1.893174  0.755919
 2.603100  0.277745  1.580109  0.314501
>>> tuples = list(zip(*[['bar', 'bar', 'baz', 'baz',
...     'foo', 'foo', 'qux', 'qux'],
...     ['one', 'two', 'one', 'two',
...     'one', 'two', 'one', 'two']]))
>>> index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])
>>> df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=['A', 'B'])
>>> df2 = df[:4]
>>> df2
                     A         B
first second
bar   one    -1.053475 -0.948631
      two     0.114382 -1.381759
baz   one    -0.794990 -0.349760
      two     0.556219  0.139522
>>> stacked = df2.stack()
>>> stacked
first  second
bar    one     A   -1.053475
               B   -0.948631
       two     A    0.114382
               B   -1.381759
baz    one     A   -0.794990
               B   -0.349760
       two     A    0.556219
               B    0.139522
dtype: float64
>>> stacked.unstack()
                     A         B
first second
bar   one    -1.053475 -0.948631
      two     0.114382 -1.381759
baz   one    -0.794990 -0.349760
      two     0.556219  0.139522
>>> stacked.unstack(1)
second        one       two
first
bar   A -1.053475  0.114382
      B -0.948631 -1.381759
baz   A -0.794990  0.556219
      B -0.349760  0.139522
>>> stacked.unstack(0)
first          bar       baz
second
one    A -1.053475 -0.794990
       B -0.948631 -0.349760
two    A  0.114382  0.556219
       B -1.381759  0.139522
>>> df = pd.DataFrame({'A' : ['one', 'one', 'two', 'three'] * 3,
...     'B' : ['A', 'B', 'C'] * 4,
...     'C' : ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2,
...     'D' : np.random.randn(12),
...     'E' : np.random.randn(12)})
>>> df
        A  B    C         D         E
0     one  A  foo -2.349735 -0.555316
1     one  B  foo -0.300047 -0.999719
2     two  C  foo -1.354144 -0.412654
3   three  A  bar -0.468933  1.670101
4     one  B  bar -0.553106  0.296311
5     one  C  bar -0.637151 -0.392841
6     two  A  foo -1.574909  0.537237
7   three  B  foo  1.049323  1.409180
8     one  C  foo -0.008082 -0.245078
9     one  A  bar -0.559425 -2.270922
10    two  B  bar -0.184045  0.572356
11  three  C  bar -0.398934  0.812406
>>> pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C'])
C             bar       foo
A     B
one   A -0.559425 -2.349735
      B -0.553106 -0.300047
      C -0.637151 -0.008082
three A -0.468933       NaN
      B       NaN  1.049323
      C -0.398934       NaN
two   A       NaN -1.574909
      B -0.184045       NaN
      C       NaN -1.354144
>>> rng = pd.date_range('1/1/2012', periods=100, freq='S')
>>> ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)
>>> ts.resample('5Min').sum()
2012-01-01    22592
Freq: 5T, dtype: int32
>>> rng = pd.date_range('3/6/2012 00:00', periods=5, freq='D')
>>> ts = pd.Series(np.random.randn(len(rng)), rng)
>>>
>>>
>>> ts
2012-03-06   -0.517868
2012-03-07    1.024510
2012-03-08   -0.589384
2012-03-09    0.617926
2012-03-10    0.520510
Freq: D, dtype: float64
>>> ts_utc = ts.tz_localize('UTC')
>>>  ts_utc
  File "<stdin>", line 1
    ts_utc
    ^
IndentationError: unexpected indent
>>> ts_utc
2012-03-06 00:00:00+00:00   -0.517868
2012-03-07 00:00:00+00:00    1.024510
2012-03-08 00:00:00+00:00   -0.589384
2012-03-09 00:00:00+00:00    0.617926
2012-03-10 00:00:00+00:00    0.520510
Freq: D, dtype: float64
>>> ts_utc.tz_convert('US/Eastern')
2012-03-05 19:00:00-05:00   -0.517868
2012-03-06 19:00:00-05:00    1.024510
2012-03-07 19:00:00-05:00   -0.589384
2012-03-08 19:00:00-05:00    0.617926
2012-03-09 19:00:00-05:00    0.520510
Freq: D, dtype: float64
>>> rng = pd.date_range('1/1/2012', periods=5, freq='M')
>>> ts = pd.Series(np.random.randn(len(rng)), index=rng)
>>> ts
2012-01-31   -0.353073
2012-02-29    0.718354
2012-03-31   -0.862499
2012-04-30    2.017078
2012-05-31    0.298544
Freq: M, dtype: float64
>>> ps = ts.to_period()
>>> ps
2012-01   -0.353073
2012-02    0.718354
2012-03   -0.862499
2012-04    2.017078
2012-05    0.298544
Freq: M, dtype: float64
>>> ps.to_timestamp()
2012-01-01   -0.353073
2012-02-01    0.718354
2012-03-01   -0.862499
2012-04-01    2.017078
2012-05-01    0.298544
Freq: MS, dtype: float64
>>> prng = pd.period_range('1990Q1', '2000Q4', freq='Q-NOV')
>>>
KeyboardInterrupt
>>> ts = pd.Series(np.random.randn(len(prng)), prng)
>>>
>>> ts.index = (prng.asfreq('M', 'e') + 1).asfreq('H', 's') + 9
>>> ts.head()
1990-03-01 09:00    0.735045
1990-06-01 09:00    0.465089
1990-09-01 09:00    0.177395
1990-12-01 09:00   -0.841582
1991-03-01 09:00   -0.630138
Freq: H, dtype: float64
>>> df = pd.DataFrame({"id":[1,2,3,4,5,6], "raw_grade":['a', 'b', 'b', 'a', 'a', 'e']})
>>> df["grade"] = df["raw_grade"].astype("category")
>>> df["grade"]
0    a
1    b
2    b
3    a
4    a
5    e
Name: grade, dtype: category
Categories (3, object): [a, b, e]
>>> df["grade"].cat.categories = ["very good", "good", "very bad"]
>>> df["grade"]
0    very good
1         good
2         good
3    very good
4    very good
5     very bad
Name: grade, dtype: category
Categories (3, object): [very good, good, very bad]
>>> df["grade"] = df["grade"].cat.set_categories(["very bad", "bad", "medium", "good", "very good"])
>>> df["grade"]
0    very good
1         good
2         good
3    very good
4    very good
5     very bad
Name: grade, dtype: category
Categories (5, object): [very bad, bad, medium, good, very good]
>>> df.sort_values(by="grade")
   id raw_grade      grade
5   6         e   very bad
1   2         b       good
2   3         b       good
0   1         a  very good
3   4         a  very good
4   5         a  very good
>>> df.groupby("grade").size()
grade
very bad     1
bad          0
medium       0
good         2
very good    3
dtype: int64
>>> ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))
>>> ts = ts.cumsum()
>>> ts.plot()
<matplotlib.axes._subplots.AxesSubplot object at 0x08CBD930>
>>>
>>>  df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index,
  File "<stdin>", line 1
    df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index,
    ^
IndentationError: unexpected indent
>>> df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index,
...     columns=['A', 'B', 'C', 'D'])
>>> df = df.cumsum()
>>>  plt.figure(); df.plot(); plt.legend(loc='best')
  File "<stdin>", line 1
    plt.figure(); df.plot(); plt.legend(loc='best')
    ^
IndentationError: unexpected indent
>>> plt.figure(); df.plot(); plt.legend(loc='best')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: 'module' object is not callable
>>>
>>> ,
  File "<stdin>", line 1
    ,
    ^
SyntaxError: invalid syntax
>>> df.to_csv('foo.csv')
>>> pd.read_csv('foo.csv')
     Unnamed: 0          A          B          C          D
0    2000-01-01  -2.051595   0.164900  -1.032017  -0.519707
1    2000-01-02  -2.856926   1.419838  -0.646447  -1.434787
2    2000-01-03  -4.373432   1.926728  -1.736677  -1.944135
3    2000-01-04  -3.357849   0.519818  -1.862398  -1.896410
4    2000-01-05  -4.394012   0.473517  -2.418113  -2.016283
5    2000-01-06  -4.784833  -0.450379  -0.703773  -1.422149
6    2000-01-07  -5.130980  -0.960823   0.033256  -2.163006
7    2000-01-08  -4.912546  -2.001601   0.718042  -0.873751
8    2000-01-09  -4.614711  -3.523930   0.066069  -1.113187
9    2000-01-10  -4.397495  -4.715878   1.497028  -0.224266
10   2000-01-11  -4.477293  -5.809750   0.719233  -0.499792
11   2000-01-12  -4.477106  -5.706691   2.325934  -0.312840
12   2000-01-13  -3.570746  -5.837951   2.397760  -0.757935
13   2000-01-14  -3.618244  -5.683629   2.062139   1.518296
14   2000-01-15  -4.799800  -4.647897   1.904955   0.871297
15   2000-01-16  -5.424743  -5.194450   2.724548   0.121533
16   2000-01-17  -6.398734  -4.276536   3.671009   1.171894
17   2000-01-18  -5.706116  -4.294125   3.368205   2.056611
18   2000-01-19  -6.211679  -3.673871   2.501434   1.978955
19   2000-01-20  -5.288569  -4.889579   2.715364   2.916197
20   2000-01-21  -5.715284  -5.775122   1.836822   2.220153
21   2000-01-22  -5.323737  -4.158285   1.461651   1.478312
22   2000-01-23  -5.381454  -3.842556   1.535141   0.289371
23   2000-01-24  -5.690679  -2.626084   0.305256   1.401362
24   2000-01-25  -6.537846  -3.091246  -0.424007   2.124757
25   2000-01-26  -5.894082  -3.068127  -1.528730   2.145470
26   2000-01-27  -6.094992  -2.226503  -1.120853   3.102827
27   2000-01-28  -5.925350  -3.231674  -1.319842   2.636048
28   2000-01-29  -6.888487  -3.260492  -2.084806   5.621100
29   2000-01-30  -7.238322  -2.251462  -2.191095   4.543897
..          ...        ...        ...        ...        ...
970  2002-08-28 -20.427708 -38.363917 -39.882597 -15.733241
971  2002-08-29 -21.580993 -37.259992 -39.055545 -16.850731
972  2002-08-30 -21.803571 -37.043136 -38.292520 -15.255083
973  2002-08-31 -20.144676 -37.603982 -38.042948 -13.748414
974  2002-09-01 -18.788711 -36.544593 -38.353403 -13.655534
975  2002-09-02 -18.218226 -35.443158 -39.614978 -14.680774
976  2002-09-03 -18.052150 -36.264395 -39.633660 -15.602394
977  2002-09-04 -18.409078 -37.154041 -40.768060 -17.510658
978  2002-09-05 -19.593685 -35.204786 -41.983646 -17.609968
979  2002-09-06 -20.810399 -34.415507 -43.354918 -17.581316
980  2002-09-07 -22.414151 -33.366538 -43.980006 -18.761787
981  2002-09-08 -22.469142 -32.935896 -43.121201 -19.044666
982  2002-09-09 -22.771955 -32.484409 -42.848318 -19.513051
983  2002-09-10 -25.195355 -33.637315 -42.868300 -18.948466
984  2002-09-11 -24.595800 -33.729233 -42.676725 -19.812084
985  2002-09-12 -23.322724 -34.073419 -42.155830 -20.675656
986  2002-09-13 -25.350432 -32.321803 -42.742646 -19.786290
987  2002-09-14 -23.886398 -33.545073 -42.524837 -19.217970
988  2002-09-15 -23.170059 -31.947554 -41.612830 -18.935707
989  2002-09-16 -21.596593 -32.502622 -42.344075 -20.022721
990  2002-09-17 -21.875919 -31.985690 -43.723491 -21.352394
991  2002-09-18 -23.413701 -31.611490 -45.362715 -21.253379
992  2002-09-19 -23.484683 -31.049603 -43.923276 -22.730592
993  2002-09-20 -22.680408 -30.114293 -42.181047 -21.571551
994  2002-09-21 -22.959585 -30.150216 -42.551784 -22.089223
995  2002-09-22 -24.387517 -31.803857 -42.021927 -24.533083
996  2002-09-23 -24.424331 -32.536895 -40.808740 -23.728424
997  2002-09-24 -23.058175 -31.100126 -40.360778 -23.935915
998  2002-09-25 -23.300612 -30.431881 -41.229386 -23.608361
999  2002-09-26 -24.075084 -29.775021 -41.141965 -22.130945

[1000 rows x 5 columns]
>>>
>>> df.to_hdf('foo.h5','df')
Traceback (most recent call last):
  File "C:\python\lib\site-packages\pandas\io\pytables.py", line 445, in __init__
    import tables  # noqa
ModuleNotFoundError: No module named 'tables'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "C:\python\lib\site-packages\pandas\core\generic.py", line 1471, in to_hdf
    return pytables.to_hdf(path_or_buf, key, self, **kwargs)
  File "C:\python\lib\site-packages\pandas\io\pytables.py", line 280, in to_hdf
    complib=complib) as store:
  File "C:\python\lib\site-packages\pandas\io\pytables.py", line 448, in __init__
    'importing'.format(ex=str(ex)))
ImportError: HDFStore requires PyTables, "No module named 'tables'" problem importing
>>> df.to_hdf('foo.h5','df')
Traceback (most recent call last):
  File "C:\python\lib\site-packages\pandas\io\pytables.py", line 445, in __init__
    import tables  # noqa
ModuleNotFoundError: No module named 'tables'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "C:\python\lib\site-packages\pandas\core\generic.py", line 1471, in to_hdf
    return pytables.to_hdf(path_or_buf, key, self, **kwargs)
  File "C:\python\lib\site-packages\pandas\io\pytables.py", line 280, in to_hdf
    complib=complib) as store:
  File "C:\python\lib\site-packages\pandas\io\pytables.py", line 448, in __init__
    'importing'.format(ex=str(ex)))
ImportError: HDFStore requires PyTables, "No module named 'tables'" problem importing
>>> pd.read_hdf('foo.h5','df')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "C:\python\lib\site-packages\pandas\io\pytables.py", line 347, in read_hdf
    'File %s does not exist' % path_or_buf)
FileNotFoundError: File foo.h5 does not exist
>>>